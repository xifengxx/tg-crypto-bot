# news_database.py
import os
from pymongo import MongoClient
import logging
from datetime import datetime, timedelta
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# å°è¯•ä»configå¯¼å…¥MONGO_URIï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
try:
    from config import MONGO_URI
    logger.info("æˆåŠŸä» config.py å¯¼å…¥ MONGO_URI")
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥ config æ¨¡å—ï¼Œå°†ä½¿ç”¨ç¯å¢ƒå˜é‡")
    
    # ä¼˜å…ˆä½¿ç”¨MongoDB Atlasçš„è¿æ¥å­—ç¬¦ä¸²
    MONGO_URI = os.environ.get('MONGODB_ATLAS_URI') or os.environ.get('MONGODB_URL') or os.environ.get('MONGODB_URI', 'mongodb://localhost:27017')
    
    # æ‰“å°MongoDB URIçš„ä¸€éƒ¨åˆ†ï¼Œé¿å…æ³„éœ²æ•æ„Ÿä¿¡æ¯
    if MONGO_URI:
        uri_parts = MONGO_URI.split('@')
        if len(uri_parts) > 1:
            masked_uri = f"{uri_parts[0].split('://')[0]}://***:***@{uri_parts[1]}"
        else:
            masked_uri = MONGO_URI
        logger.info(f"ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ MONGO_URI: {masked_uri}")
    
    # æ£€æŸ¥MongoDB URIæ ¼å¼
    if not MONGO_URI or ':@:' in MONGO_URI:
        logger.error("MongoDB URI æ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨é»˜è®¤æœ¬åœ°è¿æ¥")
        MONGO_URI = 'mongodb://localhost:27017'

# è¿æ¥åˆ°MongoDB
try:
    # æ£€æŸ¥è¿è¡Œç¯å¢ƒ
    is_railway = os.environ.get('RAILWAY_ENVIRONMENT') is not None
    environment_name = "Railwayç¯å¢ƒ" if is_railway else "æœ¬åœ°ç¯å¢ƒ"
    logger.info(f"ğŸŒ å½“å‰åœ¨ã€{environment_name}ã€‘ä¸­è¿æ¥æ•°æ®åº“")
    
    # æ·»åŠ è¿æ¥è¶…æ—¶è®¾ç½®å’Œé‡è¯•é€»è¾‘
    client = MongoClient(MONGO_URI, 
                        serverSelectionTimeoutMS=5000,
                        retryWrites=True,
                        connectTimeoutMS=30000,
                        socketTimeoutMS=45000)
    
    # æµ‹è¯•è¿æ¥
    client.admin.command('ping')
    
    # ä½¿ç”¨å›ºå®šçš„æ•°æ®åº“åç§°ï¼Œä¸å†æ ¹æ®ç¯å¢ƒåŒºåˆ†
    db = client["crypto_news"]
    
    # åˆ›å»ºé›†åˆ
    news_collection = db["news"]
    
    # åˆ›å»ºç´¢å¼•ä»¥ç¡®ä¿æ–°é—»çš„å”¯ä¸€æ€§
    news_collection.create_index([("unique_id", 1)], unique=True, sparse=True, name="unique_id_index")
    news_collection.create_index([("title", 1)], name="title_index_non_unique")
    
    logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ° MongoDB Atlas")
except Exception as e:
    logger.error(f"âŒ MongoDB è¿æ¥å¤±è´¥: {e}")
    logger.exception("MongoDB è¿æ¥è¯¦ç»†é”™è¯¯")
    
    # åˆ›å»ºä¸€ä¸ªå¤‡ç”¨çš„å†…å­˜å­˜å‚¨ï¼Œä»¥é˜²æ•°æ®åº“è¿æ¥å¤±è´¥
    class FallbackCollection:
        def __init__(self):
            self.data = []
            
        def insert_one(self, document):
            self.data.append(document)
            return True
            
        def find(self, query=None):
            # ç®€å•å®ç°æŸ¥è¯¢åŠŸèƒ½
            if not query:
                return self.data
            
            # å¤„ç†æ—¶é—´æŸ¥è¯¢
            if query.get("created_at", {}).get("$gte"):
                min_time = query["created_at"]["$gte"]
                return [doc for doc in self.data if doc.get("created_at", datetime.min) >= min_time]
            
            return self.data
            
        def create_index(self, *args, **kwargs):
            pass
        
        def sort(self, field_name=None, direction=None):
            """
            æ¨¡æ‹Ÿ MongoDB çš„ sort æ–¹æ³•
            """
            # ç®€å•å®ç°ï¼Œä¸åšå®é™…æ’åº
            return self
        
        def find_one(self, query):
            """
            æ¨¡æ‹Ÿ MongoDB çš„ find_one æ–¹æ³•
            """
            for doc in self.data:
                match = True
                for key, value in query.items():
                    if key not in doc or doc[key] != value:
                        match = False
                        break
                if match:
                    return doc
            return None
        
        def update_one(self, filter_query, update_query, upsert=False):
            """
            æ¨¡æ‹Ÿ MongoDB çš„ update_one æ–¹æ³•ï¼Œæ”¯æŒ upsert æ“ä½œ
            
            Args:
                filter_query (dict): æŸ¥è¯¢æ¡ä»¶
                update_query (dict): æ›´æ–°æ“ä½œ
                upsert (bool): å¦‚æœä¸º Trueï¼Œå½“æ–‡æ¡£ä¸å­˜åœ¨æ—¶æ’å…¥æ–°æ–‡æ¡£
            
            Returns:
                UpdateResult: åŒ…å« upserted_id å±æ€§çš„æ¨¡æ‹Ÿæ›´æ–°ç»“æœå¯¹è±¡
            """
            # æŸ¥æ‰¾åŒ¹é…çš„æ–‡æ¡£
            existing_doc = None
            for doc in self.data:
                match = True
                for key, value in filter_query.items():
                    if key not in doc or doc[key] != value:
                        match = False
                        break
                if match:
                    existing_doc = doc
                    break
            
            # å¦‚æœæ‰¾åˆ°æ–‡æ¡£ï¼Œæ›´æ–°å®ƒ
            if existing_doc:
                if "$set" in update_query:
                    for key, value in update_query["$set"].items():
                        existing_doc[key] = value
                return type('UpdateResult', (), {'upserted_id': None})()
            
            # å¦‚æœæ²¡æ‰¾åˆ°æ–‡æ¡£ä¸” upsert=Trueï¼Œåˆ›å»ºæ–°æ–‡æ¡£
            elif upsert:
                new_doc = {}
                # æ·»åŠ æŸ¥è¯¢æ¡ä»¶åˆ°æ–°æ–‡æ¡£
                new_doc.update(filter_query)
                # æ·»åŠ æ›´æ–°å†…å®¹
                if "$set" in update_query:
                    new_doc.update(update_query["$set"])
                self.data.append(new_doc)
                return type('UpdateResult', (), {'upserted_id': id(new_doc)})()
            
            # å¦‚æœæ²¡æ‰¾åˆ°æ–‡æ¡£ä¸” upsert=Falseï¼Œè¿”å›æ— æ›´æ–°ç»“æœ
            return type('UpdateResult', (), {'upserted_id': None})()
    
    news_collection = FallbackCollection()
    logger.warning("âš ï¸ ä½¿ç”¨å†…å­˜å­˜å‚¨ä½œä¸ºå¤‡ç”¨")

# æ’å…¥æ–°é—»åˆ°æ•°æ®åº“
# ä¿®æ”¹ç¬¬ä¸€å¤„ï¼šå°†è¯¦ç»†çš„è·³è¿‡æ—¥å¿—æ”¹ä¸ºè®¡æ•°ç»Ÿè®¡
# åœ¨store_newså‡½æ•°å¼€å¤´æ·»åŠ è®¡æ•°å˜é‡
def store_news(news_list):
    """
    å°†æ–°é—»æ•°æ®å­˜å…¥ MongoDB, é¿å…é‡å¤å­˜å‚¨, å¹¶è¿”å›æ–°å¢æ¡æ•°
    
    Args:
        news_list (list): æ–°é—»åˆ—è¡¨
        
    Returns:
        int: æ–°å¢çš„æ–°é—»æ•°é‡
    """
    if not news_list:
        logger.info("âš ï¸ æ²¡æœ‰æ–°çš„æ–°é—»éœ€è¦å­˜å‚¨")
        return 0
    
    # è®°å½•å·²å¤„ç†çš„æ–°é—»æ ‡è¯†ï¼Œç”¨äºæœ¬æ¬¡æ‰¹é‡å¤„ç†ä¸­çš„å»é‡
    processed_ids = set()
    new_count = 0
    skip_count = 0  # æ–°å¢ï¼šè®°å½•è·³è¿‡çš„æ–°é—»æ•°é‡
    
    for news in news_list:
        try:
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            if 'title' not in news or not news['title']:
                logger.warning(f"è·³è¿‡æ— æ ‡é¢˜æ–°é—»: {news}")
                continue
                
            if 'source' not in news or not news['source']:
                news['source'] = "Unknown"
                
            # ç”Ÿæˆå”¯ä¸€æ ‡è¯† - åªä½¿ç”¨æ ‡é¢˜å’Œæ¥æºï¼Œä¸ä½¿ç”¨æ—¶é—´
            # è¿™æ ·å³ä½¿æ—¶é—´ä¸åŒï¼Œç›¸åŒæ ‡é¢˜å’Œæ¥æºçš„æ–°é—»ä¹Ÿä¼šè¢«è§†ä¸ºé‡å¤
            unique_id = f"{news['source']}_{news['title']}"
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å½“å‰æ‰¹æ¬¡ä¸­å·²å¤„ç†è¿‡
            if unique_id in processed_ids:
                logger.debug(f"å½“å‰æ‰¹æ¬¡ä¸­å·²å¤„ç†è¿‡æ­¤æ–°é—»ï¼Œè·³è¿‡")
                skip_count += 1
                continue
            
            # æ·»åŠ åˆ°å·²å¤„ç†é›†åˆ
            processed_ids.add(unique_id)
            
            # å…ˆæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨
            existing_news = news_collection.find_one({
                "unique_id": unique_id
            })
            
            if existing_news:
                # ä¿®æ”¹ï¼šä¸å†è¾“å‡ºæ¯æ¡æ–°é—»çš„æ ‡é¢˜ï¼Œåªå¢åŠ è®¡æ•°
                skip_count += 1
                continue
                
            # ä½¿ç”¨ update_one é…åˆ upsert=True
            result = news_collection.update_one(
                {
                    "unique_id": unique_id
                },
                {
                    "$set": {
                        **news,
                        "unique_id": unique_id,  # æ·»åŠ å”¯ä¸€æ ‡è¯†
                        "created_at": datetime.utcnow(),
                        "source": news.get("source", "Unknown"),
                        "time": news.get("time", datetime.utcnow().isoformat()),
                        "last_updated": datetime.utcnow()
                    }
                },
                upsert=True
            )
            
            # å¦‚æœæ˜¯æ–°æ’å…¥çš„æ–‡æ¡£ï¼Œå¢åŠ è®¡æ•°
            if result.upserted_id:
                new_count += 1
                # ä¿®æ”¹ï¼šä¸å†è¾“å‡ºæ¯æ¡æ–°é—»çš„æ ‡é¢˜ï¼Œåªå¢åŠ è®¡æ•°
                # logger.info(f"æ–°å¢æ–°é—»: {news['title']}")
                
        except Exception as e:
            logger.error(f"å­˜å‚¨æ–°é—»æ—¶å‡ºé”™: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯")
            continue

    # åœ¨å¾ªç¯ç»“æŸåè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    if new_count > 0:
        logger.info(f"âœ… å­˜å‚¨å®Œæˆï¼šæ–°å¢ {new_count} æ¡æ–°é—»ï¼Œè·³è¿‡ {skip_count} æ¡å·²å­˜åœ¨æ–°é—»")
    else:
        logger.info(f"âœ… å­˜å‚¨å®Œæˆï¼šæ— æ–°å¢æ–°é—»ï¼Œè·³è¿‡ {skip_count} æ¡å·²å­˜åœ¨æ–°é—»")
    return new_count