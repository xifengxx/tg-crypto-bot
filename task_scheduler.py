
from apscheduler.schedulers.asyncio import AsyncIOScheduler
# from news_scraper import fetch_binance_news
from news_scraper import fetch_binance_news, fetch_okx_news, fetch_bitget_news, fetch_bybit_news, fetch_kucoin_news, fetch_gate_news

from news_database import store_news
from bot import send_latest_news  # âœ… å¯¼å…¥è‡ªåŠ¨æ¨é€æ–¹æ³•
import asyncio
import time


# å®šæ—¶ä»»åŠ¡
async def job():
    """
    1. æŠ“å–æ–°é—»
    2. å­˜å…¥æ•°æ®åº“ï¼ˆå»é‡ï¼‰
    3. **ä»…å½“æœ‰æ–°å†…å®¹æ—¶** æ¨é€åˆ° Telegram
    """
    print("ğŸ” å¼€å§‹æŠ“å– Binanceã€OKXã€Bitgetã€Bybitã€KuCoin å’Œ Gate.io çš„æ–°é—»...")

    # å¹¶è¡ŒæŠ“å–æ‰€æœ‰äº¤æ˜“æ‰€çš„æ–°é—»
    binance_news = await fetch_binance_news()
    okx_news = await fetch_okx_news()
    bitget_news = await fetch_bitget_news()
    bybit_news = await fetch_bybit_news()
    kucoin_news = await fetch_kucoin_news()  # æ–°å¢
    gate_news = await fetch_gate_news()      # æ–°å¢
    
    # åˆå¹¶æ‰€æœ‰æ–°é—»
    all_news = (
        binance_news + 
        okx_news + 
        bitget_news + 
        bybit_news + 
        kucoin_news +  # æ–°å¢
        gate_news      # æ–°å¢
    )
    
    # å­˜å…¥æ•°æ®åº“
    new_count = store_news(all_news)

    if new_count > 0:
        print(f"ğŸ“¢ å‘ç° {new_count} æ¡æ–°æ–°é—»ï¼Œå‡†å¤‡æ¨é€åˆ° Telegram...")
        await send_latest_news()  # âœ… åªæœ‰æœ‰æ–°å†…å®¹æ—¶æ‰æ¨é€
    else:
        print("â³ æ— æ–°å†…å®¹ï¼Œè·³è¿‡æ¨é€")
    



# æ·»åŠ  start_scheduler å‡½æ•°ï¼ŒåŒæ—¶ä¿ç•™åŸæœ‰åŠŸèƒ½

# task_scheduler.py
import asyncio
import logging
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import os
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
# åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥è¶…æ—¶å¤„ç†å·¥å…·
from utils import timeout
import logging

logger = logging.getLogger(__name__)

# ä¿®æ”¹å®šæ—¶ä»»åŠ¡å‡½æ•°
async def scheduled_task():
    """
    å®šæ—¶æ‰§è¡Œçš„ä»»åŠ¡ï¼ŒåŒ…å«è¶…æ—¶å¤„ç†æœºåˆ¶
    
    æ¯30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼ŒæŠ“å–æ–°é—»å¹¶æ¨é€åˆ° Telegram å’Œ Lark
    å¦‚æœæ‰§è¡Œæ—¶é—´è¶…è¿‡25åˆ†é’Ÿï¼Œä¼šè‡ªåŠ¨ç»ˆæ­¢ä»»åŠ¡
    """
    try:
        # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º25åˆ†é’Ÿï¼ˆ1500ç§’ï¼‰
        # ç”±äºä»»åŠ¡é—´éš”ä¸º30åˆ†é’Ÿï¼Œè®¾ç½®25åˆ†é’Ÿçš„è¶…æ—¶ç¡®ä¿ä¸‹ä¸€ä¸ªä»»åŠ¡èƒ½æ­£å¸¸æ‰§è¡Œ
        with timeout(1500):
            logger.info("å¼€å§‹æ‰§è¡Œå®šæ—¶ä»»åŠ¡...")
            start_time = datetime.now()
            
            # å¯¼å…¥å¿…è¦çš„æ¨¡å—
            from news_scraper import main as scraper_main
            from news_database import store_news
            from bot import send_latest_news
            
            try:
                # æŠ“å–æ–°é—»ï¼Œè®¾ç½®æ€»è¶…æ—¶ä¸º20åˆ†é’Ÿ
                news_list = await asyncio.wait_for(scraper_main(), timeout=1200)
                logger.info(f"æŠ“å–å®Œæˆï¼Œè·å–åˆ° {len(news_list)} æ¡æ–°é—»")
                
                # å­˜å‚¨æ–°é—»
                new_count = store_news(news_list)
                
                # æ¨é€æ–°é—»
                if new_count > 0:
                    logger.info(f"å‘ç° {new_count} æ¡æ–°æ–°é—»ï¼Œå‡†å¤‡æ¨é€...")
                    await send_latest_news()
                else:
                    logger.info("æ— æ–°å†…å®¹ï¼Œè·³è¿‡æ¨é€")
            except asyncio.TimeoutError:
                logger.error("æ–°é—»æŠ“å–è¶…æ—¶ï¼Œè·³è¿‡æœ¬æ¬¡ä»»åŠ¡")
                
            # è®°å½•ä»»åŠ¡æ‰§è¡Œæ—¶é—´
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            logger.info(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶ {duration:.2f} ç§’")
            
    except TimeoutError as e:
        logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œè¶…æ—¶: {e}")
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ¸…ç†ä»£ç ï¼Œä¾‹å¦‚å…³é—­è¿æ¥ç­‰
    except Exception as e:
        logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {e}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯")

def start_scheduler():
    """
    å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    """
    # åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
    scheduler = AsyncIOScheduler()
    
    # æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼Œæ¯30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    scheduler.add_job(scheduled_task, 'interval', minutes=30, id='news_scraper')
    
    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler.start()
    logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œæ¯30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡æŠ“å–ä»»åŠ¡")
    
    return scheduler

# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œåˆ™å¯åŠ¨è°ƒåº¦å™¨å¹¶ä¿æŒè¿è¡Œ
if __name__ == "__main__":
    # åˆ›å»ºäº‹ä»¶å¾ªç¯
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler = start_scheduler()
    
    try:
        # ä¿æŒç¨‹åºè¿è¡Œ
        loop.run_forever()
    except (KeyboardInterrupt, SystemExit):
        # å…³é—­è°ƒåº¦å™¨
        scheduler.shutdown()
        logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")