
from apscheduler.schedulers.asyncio import AsyncIOScheduler
# from news_scraper import fetch_binance_news
from news_scraper import fetch_binance_news, fetch_okx_news, fetch_bitget_news, fetch_bybit_news, fetch_kucoin_news, fetch_gate_news

from news_database import store_news
from bot import send_latest_news  # âœ… å¯¼å…¥è‡ªåŠ¨æ¨é€æ–¹æ³•
import asyncio
import time


# å®šæ—¶ä»»åŠ¡
async def job():
    """
    1. æŠ“å–æ–°é—»
    2. å­˜å…¥æ•°æ®åº“ï¼ˆå»é‡ï¼‰
    3. **ä»…å½“æœ‰æ–°å†…å®¹æ—¶** æ¨é€åˆ° Telegram
    """
    print("ğŸ” å¼€å§‹æŠ“å– Binanceã€OKXã€Bitgetã€Bybitã€KuCoin å’Œ Gate.io çš„æ–°é—»...")

    # å¹¶è¡ŒæŠ“å–æ‰€æœ‰äº¤æ˜“æ‰€çš„æ–°é—»
    binance_news = await fetch_binance_news()
    okx_news = await fetch_okx_news()
    bitget_news = await fetch_bitget_news()
    bybit_news = await fetch_bybit_news()
    kucoin_news = await fetch_kucoin_news()  # æ–°å¢
    gate_news = await fetch_gate_news()      # æ–°å¢
    
    # åˆå¹¶æ‰€æœ‰æ–°é—»
    all_news = (
        binance_news + 
        okx_news + 
        bitget_news + 
        bybit_news + 
        kucoin_news +  # æ–°å¢
        gate_news      # æ–°å¢
    )
    
    # å­˜å…¥æ•°æ®åº“
    new_count = store_news(all_news)

    if new_count > 0:
        print(f"ğŸ“¢ å‘ç° {new_count} æ¡æ–°æ–°é—»ï¼Œå‡†å¤‡æ¨é€åˆ° Telegram...")
        await send_latest_news()  # âœ… åªæœ‰æœ‰æ–°å†…å®¹æ—¶æ‰æ¨é€
    else:
        print("â³ æ— æ–°å†…å®¹ï¼Œè·³è¿‡æ¨é€")
    



# æ·»åŠ  start_scheduler å‡½æ•°ï¼ŒåŒæ—¶ä¿ç•™åŸæœ‰åŠŸèƒ½

# task_scheduler.py
import asyncio
import logging
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥æ‰€éœ€æ¨¡å—
try:
    from news_scraper import main as scraper_main
    from bot import send_latest_news
except ImportError as e:
    logger.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    # åˆ›å»ºå¤‡ç”¨å‡½æ•°
    async def scraper_main():
        logger.warning("æ— æ³•å¯¼å…¥ news_scraper æ¨¡å—ï¼Œè¿”å›ç©ºåˆ—è¡¨")
        return []
    
    async def send_latest_news():
        logger.warning("æ— æ³•å¯¼å…¥ bot æ¨¡å—ï¼Œè·³è¿‡å‘é€æ¶ˆæ¯")

# åˆ›å»ºè°ƒåº¦å™¨
scheduler = AsyncIOScheduler()

# å®šä¹‰ä»»åŠ¡å‡½æ•°
async def scheduled_task():
    """
    å®šæ—¶æ‰§è¡Œçš„ä»»åŠ¡ï¼šæŠ“å–æ–°é—»å¹¶å‘é€
    """
    try:
        logger.info("å¼€å§‹æ‰§è¡Œå®šæ—¶æŠ“å–ä»»åŠ¡...")
        news_list = await scraper_main()
        logger.info(f"å®šæ—¶æŠ“å–å®Œæˆï¼Œè·å–åˆ° {len(news_list)} æ¡æ–°é—»")
        
        # å‘é€æœ€æ–°æ–°é—»
        await send_latest_news()
    except Exception as e:
        logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {e}")

def start_scheduler():
    """
    å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    """
    # æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼Œæ¯30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    scheduler.add_job(scheduled_task, 'interval', minutes=30, id='news_scraper')
    
    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler.start()
    logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œæ¯30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡æŠ“å–ä»»åŠ¡")
    
    return scheduler

# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œåˆ™å¯åŠ¨è°ƒåº¦å™¨å¹¶ä¿æŒè¿è¡Œ
if __name__ == "__main__":
    # åˆ›å»ºäº‹ä»¶å¾ªç¯
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler = start_scheduler()
    
    try:
        # ä¿æŒç¨‹åºè¿è¡Œ
        loop.run_forever()
    except (KeyboardInterrupt, SystemExit):
        # å…³é—­è°ƒåº¦å™¨
        scheduler.shutdown()
        logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")