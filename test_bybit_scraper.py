# test_bybit_scraper.py
import asyncio
import aiohttp
import json
from datetime import datetime, timedelta

# ç»Ÿä¸€å¤„ç†æ–°é—»æ—¶é—´æ ¼å¼
def format_news_time(news_time):
    """
    ç»Ÿä¸€å¤„ç†æ–°é—»æ—¶é—´çš„æ ¼å¼
    æ”¯æŒå¤šç§æ ¼å¼ï¼š
    1. '2025-02-27'
    2. 'Published on Feb 20, 2025'
    3. '2025-03-03 10:41'
    4. 'Feb 26, 2025'
    5. '03/12/2025, 03:12:02'
    6. '1 hours 6 min 16 sec ago'
    7. '2 days ago'
    8. '3 minutes ago'
    è¿”å›ç»Ÿä¸€æ ¼å¼çš„æ—¶é—´ï¼š'YYYY-MM-DD HH:MM:SS UTC'
    """
    # å¤„ç†ç›¸å¯¹æ—¶é—´æ ¼å¼
    try:
        if "ago" in news_time.lower():
            now = datetime.now()
            parts = news_time.lower().split()
            
            if "day" in parts[1]:
                days = int(parts[0])
                result_time = now - timedelta(days=days)
            elif "hour" in parts[1]:
                hours = int(parts[0])
                minutes = int(parts[2]) if len(parts) > 4 and "min" in parts[3] else 0
                result_time = now - timedelta(hours=hours, minutes=minutes)
            elif "minute" in parts[1] or "min" in parts[1]:
                minutes = int(parts[0])
                result_time = now - timedelta(minutes=minutes)
            elif "second" in parts[1] or "sec" in parts[1]:
                seconds = int(parts[0])
                result_time = now - timedelta(seconds=seconds)
            else:
                return now.strftime("%Y-%m-%d %H:%M:%S UTC")
                
            return result_time.strftime("%Y-%m-%d %H:%M:%S UTC")
    except (ValueError, IndexError):
        pass

    # ä¿ç•™åŸæœ‰çš„æ ¼å¼å¤„ç†ä»£ç 
    try:
        if len(news_time) == 10:  # æ ¼å¼ 2025-02-27
            return datetime.strptime(news_time, "%Y-%m-%d").strftime("%Y-%m-%d 00:00:00 UTC")
    except ValueError:
        pass

    # å¤„ç†æ ¼å¼2: Published on Feb 20, 2025
    try:
        if news_time.startswith("Published on"):
            news_time = news_time[13:].strip()  # å»æ‰ "Published on"
            return datetime.strptime(news_time, "%b %d, %Y").strftime("%Y-%m-%d 00:00:00 UTC")
    except ValueError:
        pass
    # å¤„ç†æ ¼å¼3: 2025-03-03 10:41
    try:
        if len(news_time) > 10:  # æ ¼å¼ 2025-03-03 10:41
            return datetime.strptime(news_time, "%Y-%m-%d %H:%M").strftime("%Y-%m-%d %H:%M:%S UTC")
    except ValueError:
        pass

    # å¤„ç†æ ¼å¼4: Feb 26, 2025
    try:
        if len(news_time.split()) == 3:  # æ ¼å¼ Feb 26, 2025
            return datetime.strptime(news_time, "%b %d, %Y").strftime("%Y-%m-%d 00:00:00 UTC")
    except ValueError:
        pass
    
    # å¤„ç†æ ¼å¼5: æ·»åŠ å¯¹ MM/DD/YYYY, HH:MM:SS æ ¼å¼çš„æ”¯æŒ
    try:
        if '/' in news_time and ',' in news_time:
            parsed_time = datetime.strptime(news_time.strip(), "%m/%d/%Y, %H:%M:%S")
            return parsed_time.strftime("%Y-%m-%d %H:%M:%S UTC")
    except ValueError:
        pass
    
    print(f"âŒ æ— æ³•è§£ææ—¶é—´: {news_time}")
    return None

# Bybitæ–°é—»æŠ“å– - ä¿®æ”¹ç‰ˆæœ¬ï¼ˆheadless=Trueï¼‰
# ä¿®æ”¹ fetch_bybit_news å‡½æ•°ï¼Œä½¿ç”¨ Chromium è€Œä¸æ˜¯ Firefox
async def fetch_bybit_news():
    url = "https://announcements.bybit.com/?category=new_crypto&page=1"
    news_list = []
    
    print("å¼€å§‹æŠ“å– Bybit æ–°é—»...")
    
    async with async_playwright() as p:
        # ä½¿ç”¨ headless=True ä½†æ·»åŠ æ›´å¤šåæ£€æµ‹æªæ–½
        browser = await p.chromium.launch(
            headless=True,
            args=[
                "--disable-blink-features=AutomationControlled",
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-http2",
                "--disable-cache",
                "--disable-web-security",
                "--disable-gl",
                # æ·»åŠ æ›´å¤šå‚æ•°æ¥æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
                "--window-size=1920,1080",
                "--start-maximized",
                "--disable-extensions",
                "--hide-scrollbars",
                "--disable-infobars",
                "--ignore-certificate-errors",
                "--allow-running-insecure-content",
            ]
        )
        
        # åˆ›å»ºæ›´çœŸå®çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={"width": 1920, "height": 1080},
            # æ·»åŠ æ›´å¤šæµè§ˆå™¨ç‰¹å¾
            device_scale_factor=2,
            is_mobile=False,
            has_touch=False,
            locale="en-US",
            timezone_id="America/New_York",
            permissions=["geolocation"]
        )
        
        # æ·»åŠ æ›´å¤šåæ£€æµ‹è„šæœ¬
        await context.add_init_script("""
            // è¦†ç›– webdriver å±æ€§
            Object.defineProperty(navigator, 'webdriver', {
                get: () => false
            });
            
            // æ·»åŠ æ›´å¤šæµè§ˆå™¨ç‰¹å¾
            Object.defineProperty(navigator, 'languages', {
                get: () => ['en-US', 'en', 'zh-CN']
            });
            
            // æ¨¡æ‹Ÿ Chrome æ’ä»¶
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            
            // è¦†ç›– Permissions API
            const originalQuery = window.navigator.permissions.query;
            window.navigator.permissions.query = (parameters) => (
                parameters.name === 'notifications' ?
                Promise.resolve({ state: Notification.permission }) :
                originalQuery(parameters)
            );
            
            // æ·»åŠ  Canvas æŒ‡çº¹å¹²æ‰°
            const originalGetImageData = CanvasRenderingContext2D.prototype.getImageData;
            CanvasRenderingContext2D.prototype.getImageData = function (x, y, w, h) {
                const imageData = originalGetImageData.call(this, x, y, w, h);
                const pixels = imageData.data;
                // è½»å¾®ä¿®æ”¹åƒç´ å€¼ï¼Œä½†ä¸æ˜æ˜¾æ”¹å˜å›¾åƒ
                for (let i = 0; i < pixels.length; i += 4) {
                    pixels[i] = pixels[i] + Math.floor(Math.random() * 2);
                    pixels[i+1] = pixels[i+1] + Math.floor(Math.random() * 2);
                    pixels[i+2] = pixels[i+2] + Math.floor(Math.random() * 2);
                }
                return imageData;
            };
        """)
        
        page = await context.new_page()
        
        # æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
        await page.mouse.move(100, 100)
        await page.mouse.down()
        # ä¿®å¤ï¼šç§»é™¤é¢å¤–çš„å‚æ•°ï¼ŒPythonç‰ˆæœ¬çš„move()ä¸æ”¯æŒstepså‚æ•°
        await page.mouse.move(200, 200)
        await page.mouse.up()

        try:
            print("æ­£åœ¨åŠ è½½ Bybit é¡µé¢...")
            
            # ä½¿ç”¨ä»£ç†ï¼ˆå¦‚æœæœ‰ï¼‰
            # await context.route('**/*', lambda route: route.continue_(
            #     headers={
            #         **route.request.headers,
            #         'X-Forwarded-For': '123.45.67.89'  # éšæœº IP
            #     }
            # ))
            
            # å¢åŠ é‡è¯•æœºåˆ¶
            max_retries = 5  # å¢åŠ é‡è¯•æ¬¡æ•°
            for attempt in range(max_retries):
                try:
                    print(f"å°è¯•åŠ è½½é¡µé¢ (å°è¯• {attempt+1}/{max_retries})...")
                    
                    # ä½¿ç”¨ä¸åŒçš„åŠ è½½ç­–ç•¥
                    if attempt % 2 == 0:
                        await page.goto(url, wait_until="networkidle", timeout=90000)
                    else:
                        await page.goto(url, wait_until="load", timeout=90000)
                    
                    # æ£€æŸ¥é¡µé¢æ˜¯å¦åŠ è½½æˆåŠŸ
                    content = await page.content()
                    if "article-list" in content:
                        print("é¡µé¢æˆåŠŸåŠ è½½ï¼ŒåŒ…å«ç›®æ ‡å†…å®¹")
                        break
                    
                    print("é¡µé¢åŠ è½½å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›®æ ‡å†…å®¹ï¼Œå°†é‡è¯•...")
                    await page.wait_for_timeout(3000 * (attempt + 1))  # é€’å¢ç­‰å¾…æ—¶é—´
                    
                except Exception as e:
                    print(f"åŠ è½½é¡µé¢å¤±è´¥: {e}")
                    if attempt == max_retries - 1:
                        raise
                    await page.wait_for_timeout(5000 * (attempt + 1))  # é€’å¢ç­‰å¾…æ—¶é—´
            
            print("é¡µé¢åˆæ­¥åŠ è½½å®Œæˆ")
            
            # æ¨¡æ‹Ÿç”¨æˆ·æ»šåŠ¨é¡µé¢
            for _ in range(3):
                await page.evaluate("window.scrollBy(0, 300)")
                await page.wait_for_timeout(1000)
            
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            await page.wait_for_timeout(5000)
            
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            selector = "div.article-list"
            print(f"ç­‰å¾…é€‰æ‹©å™¨: {selector}")
            
            # æ·»åŠ é‡è¯•æœºåˆ¶ç­‰å¾…é€‰æ‹©å™¨
            for attempt in range(max_retries):
                try:
                    await page.wait_for_selector(selector, timeout=30000)
                    break
                except Exception as e:
                    print(f"ç­‰å¾…é€‰æ‹©å™¨å¤±è´¥: {e}")
                    if attempt == max_retries - 1:
                        raise
                    
                    # å°è¯•åˆ·æ–°é¡µé¢
                    if attempt > 1:
                        await page.reload(wait_until="networkidle")
                    
                    await page.wait_for_timeout(3000)
            
            # ç¡®ä¿é¡µé¢ç¨³å®šåå†è·å–å†…å®¹
            await page.wait_for_timeout(3000)
            
            # å°è¯•ç›´æ¥ä½¿ç”¨ JavaScript è·å–å†…å®¹
            news_data = await page.evaluate("""
                () => {
                    const items = Array.from(document.querySelectorAll('div.article-list a'));
                    return items.map(item => {
                        const titleEl = item.querySelector('span');
                        const timeEl = item.querySelector('div.article-item-date');
                        return {
                            title: titleEl ? titleEl.textContent.trim() : null,
                            link: item.href,
                            time: timeEl ? timeEl.textContent.trim() : 'No date found'
                        };
                    });
                }
            """)
            
            print(f"é€šè¿‡ JavaScript æ‰¾åˆ° {len(news_data)} ä¸ªæ–°é—»é¡¹")
            
            # å¦‚æœ JavaScript æ–¹æ³•æˆåŠŸï¼Œä½¿ç”¨å®ƒçš„ç»“æœ
            if news_data and len(news_data) > 0:
                for item in news_data:
                    if item['title'] and item['link']:
                        news_list.append({
                            "title": item['title'], 
                            "link": item['link'], 
                            "time": format_news_time(item['time']),
                            "source": "Bybit"
                        })
                        print(f"âœ… æˆåŠŸæŠ“å–: {item['title']} | æ—¶é—´: {item['time']}")
            else:
                # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ BeautifulSoup
                html = await page.content()
                soup = BeautifulSoup(html, "html.parser")
                print("ğŸ” ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æŠ“å– Bybit çš„æ–°é—»...")
                
                # è·å–æ‰€æœ‰æ–°é—»é¡¹
                news_items = soup.select("div.article-list a")
                print(f"æ‰¾åˆ° {len(news_items)} ä¸ªæ–°é—»é¡¹")
                
                for item in news_items:
                    title = None
                    link = item["href"] if item.get("href") else None
                    
                    title_tag = item.find("span")
                    title = title_tag.text.strip() if title_tag else None
                    
                    time_tag = item.find("div", class_="article-item-date")
                    time = time_tag.text.strip() if time_tag else "No date found"
                    
                    if title and link:
                        full_link = "https://announcements.bybit.com" + link if not link.startswith("http") else link
                        news_list.append({
                              "title": title, 
                              "link": full_link, 
                              "time": format_news_time(time),
                              "source": "Bybit"
                        })
                        print(f"âœ… æˆåŠŸæŠ“å–: {title} | æ—¶é—´: {time}")
                    else:
                        print(f"âš ï¸ è·³è¿‡æ— æ•ˆæ–°é—»é¡¹: æ ‡é¢˜={title}, é“¾æ¥={link}")
                    
        except Exception as e:
            print(f"Bybit æŠ“å–å‡ºé”™: {e}")
            print(f"\né”™è¯¯è¯¦ç»†ä¿¡æ¯:")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
            
            try:
                await page.screenshot(path="/Users/mac/tg-crypto-bot/bybit_error.png")
                print("å·²ä¿å­˜é”™è¯¯é¡µé¢æˆªå›¾åˆ° bybit_error.png")
            except Exception as screenshot_error:
                print(f"æ— æ³•ä¿å­˜æˆªå›¾: {screenshot_error}")
                
            try:
                html = await page.content()
                print("é¡µé¢HTMLå‰1000ä¸ªå­—ç¬¦:")
                print(html[:1000])
            except Exception as content_error:
                print(f"æ— æ³•è·å–é¡µé¢å†…å®¹: {content_error}")
        finally:
            await browser.close()

    # ç»Ÿè®¡ä¿¡æ¯
    total_count = len(news_list)
    unique_news = {item["title"]: item for item in news_list}.values()
    filtered_count = len(unique_news)

    print("\n=== Bybit æŠ“å–ç»Ÿè®¡ ===")
    print(f"ğŸ“Œ æ€»å…±æŠ“å– {total_count} æ¡æ–°é—»")
    print(f"ğŸ” å»é‡åå‰©ä½™ {filtered_count} æ¡æ–°é—»\n")

    print("\n=== æŠ“å–ç»“æœ ===\n")
    for item in unique_news:
        print(f"ğŸ“Œ {item['title']}\nğŸ”— {item['link']}\nğŸ“… {item['time']}\n")

    return list(unique_news)

# ä½¿ç”¨ Bybit å®˜æ–¹ API è·å–æ–°é—» (ä½¿ç”¨åŒæ­¥ requests åº“)
async def fetch_bybit_news():
    print("å¼€å§‹é€šè¿‡ Bybit å®˜æ–¹ API æŠ“å–æ–°é—»...")
    news_list = []
    
    # å¯¼å…¥ requests åº“
    import requests
    
    # Bybit å…¬å‘Š API å®˜æ–¹ç«¯ç‚¹
    url = "https://api.bybit.com/v5/announcements/index"
    
    # è¯·æ±‚å‚æ•° (æ ¹æ®å®˜æ–¹æ–‡æ¡£)
    params = {
        "locale": "en-US",  # ä½¿ç”¨è‹±æ–‡ï¼Œæ›´ç¨³å®š
        "type": "new_crypto",  # æ–°å¸ä¸Šçº¿ç±»åˆ«
        "page": 1,
        "limit": 20  # è·å–æœ€æ–°çš„20æ¡å…¬å‘Š
    }
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Accept": "application/json"
    }
    
    try:
        print(f"æ­£åœ¨è¯·æ±‚ Bybit API: {url}")
        
        # ä½¿ç”¨åŒæ­¥è¯·æ±‚ï¼Œè®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
        response = requests.get(url, params=params, headers=headers, timeout=60)
        
        print(f"API å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            
            # æ£€æŸ¥ API å“åº”ç»“æ„ (æ ¹æ®å®˜æ–¹æ–‡æ¡£)
            if data.get("retCode") == 0 and "result" in data:
                result = data["result"]
                announcements = result.get("list", [])
                print(f"è·å–åˆ° {len(announcements)} æ¡å…¬å‘Š")
                
                for item in announcements:
                    title = item.get("title")
                    url = item.get("url")
                    publish_time = item.get("publishTime")
                    description = item.get("description", "")
                    
                    if title:
                        # å¤„ç†æ—¶é—´
                        formatted_time = None
                        if publish_time:
                            try:
                                # API è¿”å›çš„æ—¶é—´é€šå¸¸æ˜¯æ¯«ç§’çº§æ—¶é—´æˆ³
                                dt = datetime.fromtimestamp(int(publish_time) / 1000)
                                formatted_time = dt.strftime("%Y-%m-%d %H:%M:%S UTC")
                            except Exception as e:
                                print(f"æ—¶é—´æ ¼å¼åŒ–é”™è¯¯: {e}, åŸå§‹æ—¶é—´: {publish_time}")
                                formatted_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC")
                        
                        news_list.append({
                            "title": title,
                            "link": url,
                            "time": formatted_time,
                            "description": description,
                            "source": "Bybit"
                        })
                        print(f"âœ… æˆåŠŸæŠ“å–: {title} | æ—¶é—´: {formatted_time}")
            else:
                error_msg = data.get("retMsg", "æœªçŸ¥é”™è¯¯")
                print(f"API å“åº”é”™è¯¯: {error_msg}")
                print(f"å®Œæ•´å“åº”: {data}")
        else:
            print(f"API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            print(response.text)
    except requests.exceptions.Timeout:
        print("API è¯·æ±‚è¶…æ—¶ï¼Œå°è¯•å¤‡ç”¨ç«¯ç‚¹...")
        # å°è¯•å¤‡ç”¨ç«¯ç‚¹
        backup_url = "https://api.bytick.com/v5/announcements/index"
        try:
            response = requests.get(backup_url, params=params, headers=headers, timeout=60)
            if response.status_code == 200:
                data = response.json()
                if data.get("retCode") == 0 and "result" in data:
                    result = data["result"]
                    announcements = result.get("list", [])
                    print(f"å¤‡ç”¨ API è·å–åˆ° {len(announcements)} æ¡å…¬å‘Š")
                    
                    for item in announcements:
                        title = item.get("title")
                        url = item.get("url")
                        publish_time = item.get("publishTime")
                        description = item.get("description", "")
                        
                        if title:
                            # å¤„ç†æ—¶é—´
                            formatted_time = None
                            if publish_time:
                                try:
                                    dt = datetime.fromtimestamp(int(publish_time) / 1000)
                                    formatted_time = dt.strftime("%Y-%m-%d %H:%M:%S UTC")
                                except Exception as e:
                                    print(f"æ—¶é—´æ ¼å¼åŒ–é”™è¯¯: {e}, åŸå§‹æ—¶é—´: {publish_time}")
                                    formatted_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC")
                            
                            news_list.append({
                                "title": title,
                                "link": url,
                                "time": formatted_time,
                                "description": description,
                                "source": "Bybit"
                            })
                            print(f"âœ… æˆåŠŸæŠ“å–: {title} | æ—¶é—´: {formatted_time}")
                else:
                    print(f"å¤‡ç”¨ API å“åº”é”™è¯¯: {data.get('retMsg', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"å¤‡ç”¨ API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except Exception as e:
            print(f"å¤‡ç”¨ API æŠ“å–å‡ºé”™: {e}")
    except Exception as e:
        print(f"Bybit API æŠ“å–å‡ºé”™: {e}")
        print(f"\né”™è¯¯è¯¦ç»†ä¿¡æ¯:")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        
    # å¦‚æœä¸»ç½‘å’Œå¤‡ç”¨ç½‘éƒ½å¤±è´¥ï¼Œå°è¯•æµ‹è¯•ç½‘
    if not news_list:
        try:
            print("\nå°è¯•æµ‹è¯•ç½‘ API...")
            test_url = "https://api-testnet.bybit.com/v5/announcements/index"
            response = requests.get(test_url, params=params, headers=headers, timeout=60)
            
            if response.status_code == 200:
                data = response.json()
                if data.get("retCode") == 0 and "result" in data:
                    result = data["result"]
                    announcements = result.get("list", [])
                    print(f"æµ‹è¯•ç½‘ API è·å–åˆ° {len(announcements)} æ¡å…¬å‘Š")
                    
                    for item in announcements:
                        title = item.get("title")
                        url = item.get("url")
                        publish_time = item.get("publishTime")
                        description = item.get("description", "")
                        
                        if title:
                            # å¤„ç†æ—¶é—´
                            formatted_time = None
                            if publish_time:
                                try:
                                    dt = datetime.fromtimestamp(int(publish_time) / 1000)
                                    formatted_time = dt.strftime("%Y-%m-%d %H:%M:%S UTC")
                                except Exception as e:
                                    print(f"æ—¶é—´æ ¼å¼åŒ–é”™è¯¯: {e}, åŸå§‹æ—¶é—´: {publish_time}")
                                    formatted_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC")
                            
                            news_list.append({
                                "title": title,
                                "link": url,
                                "time": formatted_time,
                                "description": description,
                                "source": "Bybit"
                            })
                            print(f"âœ… æˆåŠŸæŠ“å–: {title} | æ—¶é—´: {formatted_time}")
                else:
                    print(f"æµ‹è¯•ç½‘ API å“åº”é”™è¯¯: {data.get('retMsg', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"æµ‹è¯•ç½‘ API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except Exception as e:
            print(f"æµ‹è¯•ç½‘ API æŠ“å–å‡ºé”™: {e}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_count = len(news_list)
    unique_news = {item["title"]: item for item in news_list}.values()
    filtered_count = len(unique_news)

    print("\n=== Bybit æŠ“å–ç»Ÿè®¡ ===")
    print(f"ğŸ“Œ æ€»å…±æŠ“å– {total_count} æ¡æ–°é—»")
    print(f"ğŸ” å»é‡åå‰©ä½™ {filtered_count} æ¡æ–°é—»\n")

    print("\n=== æŠ“å–ç»“æœ ===\n")
    for item in unique_news:
        print(f"ğŸ“Œ {item['title']}\nğŸ”— {item['link']}\nğŸ“… {item['time']}\n")

    return list(unique_news)

# æ·»åŠ ä¸€ä¸ªè°ƒè¯•å‡½æ•°æ¥æµ‹è¯• Bybit APIï¼ˆä½¿ç”¨åŒæ­¥çš„ requests åº“ï¼‰
def debug_bybit_api_sync():
    print("å¼€å§‹ä½¿ç”¨åŒæ­¥æ–¹å¼è°ƒè¯• Bybit API...")
    
    # å¯¼å…¥ requests åº“
    import requests
    
    # Bybit å…¬å‘Š API å®˜æ–¹ç«¯ç‚¹
    url = "https://api.bybit.com/v5/announcements/index"
    
    # è¯·æ±‚å‚æ•° (æ ¹æ®å®˜æ–¹æ–‡æ¡£)
    params = {
        "locale": "en-US",  # ä½¿ç”¨è‹±æ–‡
        "type": "new_crypto",  # æ–°å¸ä¸Šçº¿ç±»åˆ«
        "page": 1,
        "limit": 5  # åªè·å–5æ¡ç”¨äºè°ƒè¯•
    }
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Accept": "application/json"
    }
    
    try:
        print(f"æ­£åœ¨è¯·æ±‚ Bybit API: {url}")
        print(f"è¯·æ±‚å‚æ•°: {params}")
        
        # è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
        response = requests.get(url, params=params, headers=headers, timeout=60)
        
        print(f"API å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            
            # æ‰“å°å®Œæ•´çš„ API å“åº”
            # print("\n=== API å“åº”å†…å®¹ ===")
            # print(json.dumps(data, indent=2, ensure_ascii=False))
            
            # æ£€æŸ¥ API å“åº”ç»“æ„
            if data.get("retCode") == 0 and "result" in data:
                result = data["result"]
                announcements = result.get("list", [])
                print(f"\nè·å–åˆ° {len(announcements)} æ¡å…¬å‘Š")
                
                # æ‰“å°ç¬¬ä¸€æ¡å…¬å‘Šçš„è¯¦ç»†ä¿¡æ¯
                if announcements:
                    print("\n=== ç¬¬ä¸€æ¡å…¬å‘Šè¯¦ç»†ä¿¡æ¯ ===")
                    first_item = announcements[0]
                    for key, value in first_item.items():
                        print(f"{key}: {value}")
            else:
                error_msg = data.get("retMsg", "æœªçŸ¥é”™è¯¯")
                print(f"API å“åº”é”™è¯¯: {error_msg}")
        else:
            print(f"API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            print(response.text)
    except requests.exceptions.Timeout:
        print("API è¯·æ±‚è¶…æ—¶ï¼Œå°è¯•å¤‡ç”¨ç«¯ç‚¹...")
        # å°è¯•å¤‡ç”¨ç«¯ç‚¹
        backup_url = "https://api.bytick.com/v5/announcements/index"
        try:
            response = requests.get(backup_url, params=params, headers=headers, timeout=60)
            if response.status_code == 200:
                data = response.json()
                print("\n=== å¤‡ç”¨ API å“åº”å†…å®¹ ===")
                print(json.dumps(data, indent=2, ensure_ascii=False))
            else:
                print(f"å¤‡ç”¨ API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except Exception as e:
            print(f"å¤‡ç”¨ API è¯·æ±‚ä¹Ÿå¤±è´¥: {e}")
    except Exception as e:
        print(f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        
    # å°è¯•ç¬¬ä¸‰ä¸ªç«¯ç‚¹ - æµ‹è¯•ç½‘
    try:
        print("\nå°è¯•æµ‹è¯•ç½‘ API...")
        test_url = "https://api-testnet.bybit.com/v5/announcements/index"
        response = requests.get(test_url, params=params, headers=headers, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            print("\n=== æµ‹è¯•ç½‘ API å“åº”å†…å®¹ ===")
            # print(json.dumps(data, indent=2, ensure_ascii=False))
        else:
            print(f"æµ‹è¯•ç½‘ API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
    except Exception as e:
        print(f"æµ‹è¯•ç½‘ API è¯·æ±‚å¤±è´¥: {e}")

# ä¿®æ”¹æµ‹è¯•å‡½æ•°
async def main():
    # ä½¿ç”¨åŒæ­¥æ–¹å¼è°ƒè¯• API
    debug_bybit_api_sync()
    
    # å¦‚æœè°ƒè¯•æˆåŠŸï¼Œå†è¿è¡Œå®Œæ•´çš„æŠ“å–å‡½æ•°
    print("\n\nè°ƒè¯•å®Œæˆï¼Œå¼€å§‹è¿è¡Œå®Œæ•´æŠ“å–å‡½æ•°...\n")
    await fetch_bybit_news()

if __name__ == "__main__":
    asyncio.run(main())